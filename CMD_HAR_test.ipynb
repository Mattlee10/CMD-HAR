{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4qugqe26Fxld3layi/Njd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mattlee10/CMD-HAR/blob/main/CMD_HAR_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut0mq5-3RQKy",
        "outputId": "3140a034-0484-409f-fcc9-be9bc2c3960b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([32, 6])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Shared Encoder\n",
        "class SharedEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(SharedEncoder, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Private Encoder\n",
        "class PrivateEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(PrivateEncoder, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Disentangler\n",
        "class Disentangler(nn.Module):\n",
        "    def __init__(self, shared_dim, private_dim, output_dim):\n",
        "        super(Disentangler, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(shared_dim + private_dim, output_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, shared, private):\n",
        "        combined = torch.cat((shared, private), dim=1)\n",
        "        return self.fc(combined)\n",
        "\n",
        "# Classifier\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# CMD-HAR 전체 구조\n",
        "class CMDHARModel(nn.Module):\n",
        "    def __init__(self, input_dim, shared_dim, private_dim, num_classes):\n",
        "        super(CMDHARModel, self).__init__()\n",
        "        self.shared_encoder = SharedEncoder(input_dim, shared_dim)\n",
        "        self.private_encoder = PrivateEncoder(input_dim, private_dim)\n",
        "        self.disentangler = Disentangler(shared_dim, private_dim, shared_dim + private_dim)\n",
        "        self.classifier = Classifier(shared_dim + private_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shared_feat = self.shared_encoder(x)\n",
        "        private_feat = self.private_encoder(x)\n",
        "        disentangled_feat = self.disentangler(shared_feat, private_feat)\n",
        "        out = self.classifier(disentangled_feat)\n",
        "        return out\n",
        "\n",
        "# 예시 실행 (Colab에서 테스트 가능)\n",
        "if __name__ == \"__main__\":\n",
        "    input_dim = 50\n",
        "    model = CMDHARModel(input_dim=input_dim, shared_dim=32, private_dim=32, num_classes=6)\n",
        "    dummy_input = torch.randn(32, input_dim)\n",
        "    output = model(dummy_input)\n",
        "    print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수 & 옵티마이저 설정\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "KmG1niB9YaXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더 준비\n",
        "# PAMAP2 데이터셋을 전처리해서 Dataset/DataLoader로 감싸기\n",
        "# batch_size=32로 설정"
      ],
      "metadata": {
        "id": "Fj26fXE1YhkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 루프(Training Loop) 작성\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# 검증 & 전이 실험\n",
        "# IMU만으로 학습한 뒤 PPG 데이터로 평가해보고\n",
        "# (accuracy, F1 등) 지표를 기록\n",
        "\n",
        "# 결과 시각화 및 기록\n",
        "# Epoch별 손실/정확도 곡선 그리기\n",
        "# 전이 성능 비교 표 정리"
      ],
      "metadata": {
        "id": "Ph8ohZ09YxK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 코드는 논문에서 제안한 Cross-Modal Disentaglement (CMD) 구조를 그대로 반영해서, 공통 특징(Private)을 분리->결합->분류 과정을 모듈화한 것"
      ],
      "metadata": {
        "id": "EIclWeueSAG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. SharedEncoder\n",
        "\n",
        "- 역할: 서로 다른 센서(IMU, PPG 등)에서 공통적으로 나타나는 패턴을 학습\n",
        "\n",
        "- 구현: 입력 특징(input_dim)을 받아 은닉공간(hidden_dim)으로 토영 -> ReLU\n",
        "\n",
        "- 이유: '사람이 걷는 신호'처럼 센서 종류에 관계없이 공유되는 행동 표현을 뽑아내기 위해"
      ],
      "metadata": {
        "id": "CHzT79LBSS4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SharedEncoder(nn.Module):\n",
        "  ...\n",
        "  self.fc = nn.Sequential(\n",
        "      nn.Linear(input_dim, hidden_dim),\n",
        "      nn.ReLU()\n",
        "  )"
      ],
      "metadata": {
        "id": "uhp_53FETlLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. PrivateEncoder\n",
        "\n",
        "- 역할: 각 센서만 갖고 있는 고유한 신호 특성을 학습\n",
        "\n",
        "- 구현: SharedEncoder와 같은 구조지만, 학습되는 파라미터가 별개\n",
        "\n",
        "- 이유: 'PPG의 맥파 형태나'나 'IMU의 가속도 진동' 같은 센서별 디테일을 따로 분리해서 표현하기 위해"
      ],
      "metadata": {
        "id": "nSmItlJJUIB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrivateEncoder(nn.Module):\n",
        "  ...\n",
        "  self.fc = nn.Sequential(\n",
        "      nn.Linear(input_dim, hidden_dim),\n",
        "      nn.ReLU()\n",
        "  )"
      ],
      "metadata": {
        "id": "LIbNdAVlUxmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Disentangler\n",
        "\n",
        "- 역할: Shared와 Private 피처를 결합(concatenate)한 뒤, 다시 '공통 <-> 고유' 특징을 효괒거으로 분리/재조합\n",
        "\n",
        "- 구현: concat(shared, private) -> 은식 출력(output_dim) -> ReLU\n",
        "\n",
        "- 이유: 단순 결합만 하면 정보가 뒤섞이기 때문에, 분리된 표현을 더 명확하게 재구성하기 위함"
      ],
      "metadata": {
        "id": "r5GQipTQVGSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Disentagler(nn.Module):\n",
        "  ...\n",
        "  combined = torch.cat((shared, private), dim=1)\n",
        "  return self.fc(combined)"
      ],
      "metadata": {
        "id": "Ldw_yBkNVyKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Classifier\n",
        "\n",
        "- 역할: Disentangler가 만든 통합 표현을 받아 최종 활동 레이블(걸음/달리기/기타) 예측\n",
        "\n",
        "- 구현: 두 개의 선형 계측 + 중간 ReLU\n",
        "\n",
        "- 이유: disentangled feature를 분류기에 투입해 HAR 과제를 해결"
      ],
      "metadata": {
        "id": "dgMF7TBbV-Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "  ...\n",
        "  self.fc = nn.Sequential(\n",
        "      nn.Linear(input_dim, 64),\n",
        "      nn.ReLU()\n",
        "      nn.Linear(64, num_classes)\n",
        "  )"
      ],
      "metadata": {
        "id": "jOBo3t4QWRqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. CMDHARModel (전체 파이프라인)\n",
        "\n",
        "- 순서:\n",
        "\n",
        "1. SharedEncoder -> 공통 피처\n",
        "2. PrivateEncoder -> 고유 피처\n",
        "3. Disentangler -> 두 피처 합성/분리\n",
        "4. Classifier -> 활동 예측\n",
        "\n",
        "- 이유: 모듈화를 통해 각 단계(공통/고유/분리/분류)를 명확히 분리하고, 실험/디버깅/확장을 쉽게 하기 위함"
      ],
      "metadata": {
        "id": "BEMTfMDXWr1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CMDHARModel(nn.Module):\n",
        "  def foward(self, x):\n",
        "      shared_feat = self.shared_encoder(x)\n",
        "      pricate_feat = self.private_encoder(x)\n",
        "      disentangled_feat = self.disentangler(shared_feat, private_feat)\n",
        "      out = self.classifier(disentangled_feat)\n",
        "      return out"
      ],
      "metadata": {
        "id": "VCj49dhKXGFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. 더미 입력 테스트\n",
        "\n",
        "- dummy_input = torch.randn(32,50)\n",
        "\n",
        "- 목적: 배치 크기 32, 특성 차원 50인 랜덤 데이터를 넣어보면서 '모델 전체가 잘 연결됐는지', '출력 차원이 (32, num_classes)인지' 확인하기 위함"
      ],
      "metadata": {
        "id": "12gIIvaWXetB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_output = model(dummy_input)\n",
        "print(\"Output shape:\", example_output.shape)"
      ],
      "metadata": {
        "id": "KTCczxX8XuaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 구조 덕분에\n",
        "\n",
        "- 센서 종류가 바뀌어도 SharedEncoder가 공통 행동 신호를 잡아내고,\n",
        "\n",
        "- PricateEncoder가 센서별 노이즈=신호를 분리해 내며,\n",
        "\n",
        "- Disentangler가 두 표현을 최적의 형태로 결합/분리해 주기 때문에\n",
        "\n",
        "- Zero-shot transfer처럼 'IMU로 학습 -> PPG에 바로 적용'이 가능해지는 것"
      ],
      "metadata": {
        "id": "v5hgqQjqXwMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset\n",
        "\n",
        "- https://archive.ics.uci.edu/dataset/231/pamap2+physical+activity+monitoring\n"
      ],
      "metadata": {
        "id": "GCvq85TWaY2k"
      }
    }
  ]
}